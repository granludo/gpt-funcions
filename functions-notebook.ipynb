{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jugant amb GPT i funcions\n",
    "Marc Alier Juny 2023\n",
    "https://wasabi.essi.upc.edu/ludo \n",
    "\n",
    "\n",
    "## Configuració\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#potser es necessari\n",
    "%pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importa la llibreria openai i carrega la teva API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "# importa la llibreria OpenAI\n",
    "import openai\n",
    "import json\n",
    "import requests\n",
    "\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "with open('..//mykey.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    print(\"OK\")\n",
    "    \n",
    "openai.api_key = data['key']\n",
    "\n",
    "# alternativament pots fer \n",
    "#\n",
    "# openai.api_key = \"posa aqui la teva clau\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definim el model al que ens conectem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL = \"gpt-3.5-turbo\"\n",
    "MODEL = \"gpt-4-0613\" # model minim per tenir funcions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Què és una funció en el context de GPT?\n",
    "\n",
    "En el context de l'API de GPT (GPT-3.5 turbo i GPT-4 a partir de 17 juny 2023) una funció és una **possibilitat que oferim al model per a respondre a les indicacions d'un usuari.** \n",
    "\n",
    "El desenvolupador descriu en llenguatge natural el que suposadament fa una funció i els paràmetres que rep aquesta funció en JSON. \n",
    "\n",
    "Si el model decideix que per a donar una bona resposta necessita invocar aquesta funció, en comptes de donar una resposta estàndard ens **retornarà una sol·licitud d'execució d'aquesta funció juntament amb els valors dels paràmetres.** \n",
    "\n",
    "### funció per cridar a GPT\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crida_a_openai(model, messages, temperature):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': f'Bearer {openai.api_key}'\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        'model': model,\n",
    "        'messages': messages,\n",
    "        'temperature': temperature\n",
    "    }\n",
    "\n",
    "    response = requests.post('https://api.openai.com/v1/chat/completions', headers=headers, data=json.dumps(data))\n",
    "\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple de crida a GPT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-7UuGKiLagklUnB2nXrqaPeurpPLka',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1687600468,\n",
       " 'model': 'gpt-4-0613',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': 'No, no, no! No obriré la porta! La meva casa està feta de maons, no la podràs ensorrar bufant!'},\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 74, 'completion_tokens': 35, 'total_tokens': 109}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "response = crida_a_openai(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Ets un dels tres porquets del \\\n",
    "        conte i ets a casa.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Pom Pom.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Quí hi ha?\"},\n",
    "        {\"role\": \"user\", \"content\": \"Soc el llop ferotge,\\\n",
    "         obre la porta o bufaré, bufaré i la casa ensorraré.\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "No, no, no! No obriré la porta! La meva casa està feta de maons, no la podràs ensorrar bufant!"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the 'content' of the 'message' in the first 'choice\n",
    "html_content = response['choices'][0]['message']['content']\n",
    "\n",
    "# Render and display the HTML content\n",
    "display(HTML(html_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ara amb funcions\n",
    "\n",
    "Anem a proposar dues funcions disponibles pel porquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crida_a_openai_amb_funcions(model, messages, functions, temperature):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': f'Bearer {openai.api_key}'\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        'model': model,\n",
    "        'messages': messages,\n",
    "        'functions': functions,\n",
    "        'temperature': temperature\n",
    "    }\n",
    "\n",
    "    response = requests.post('https://api.openai.com/v1/chat/completions', headers=headers, data=json.dumps(data))\n",
    "\n",
    "    return response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"avisa_al_cacador\",\n",
    "        \"description\": \"Avisa al caçador per demanar ajuda\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"La ubicació de la casa del porquet.\"\n",
    "                },\n",
    "                \"porquet\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"El nom del porquet que demana ajuda.\"\n",
    "                },\n",
    "                \"urgent\": {\n",
    "                    \"type\": \"boolean\",\n",
    "                    \"description\": \"Indica si l'ajuda és urgent o no.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\", \"porquet\", \"urgent\"]\n",
    "        },\n",
    "        \"results\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Un missatge que descriu la situació.\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"comunica_amb_germa\",\n",
    "        \"description\": \"Permet al porquet comunicar-se amb un dels seus germans\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"porquet\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"El nom del porquet que vol comunicar-se.\"\n",
    "                },\n",
    "                \"germa\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"El nom del germa amb qui el porquet vol comunicar-se.\"\n",
    "                },\n",
    "                \"missatge\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"El missatge que el porquet vol enviar al seu germa.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"porquet\", \"germa\", \"missatge\"]\n",
    "        },\n",
    "        \"results\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"Un missatge confirmant que el missatge ha estat enviat al germa.\"\n",
    "        }\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-7UuHLR3BZGbiMYVx9uw3zDRGOU0yS',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1687600531,\n",
       " 'model': 'gpt-4-0613',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': None,\n",
       "    'function_call': {'name': 'avisa_al_cacador',\n",
       "     'arguments': '{\\n  \"location\": \"casa del porquet\",\\n  \"porquet\": \"porquet\",\\n  \"urgent\": true\\n}'}},\n",
       "   'finish_reason': 'function_call'}],\n",
       " 'usage': {'prompt_tokens': 258, 'completion_tokens': 38, 'total_tokens': 296}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Ets un dels tres porquets del \\\n",
    "        conte i ets a casa.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Pom Pom.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Quí hi ha?\"},\n",
    "        {\"role\": \"user\", \"content\": \"Soc el llop ferotge,\\\n",
    "         obre la porta o bufaré, bufaré i la casa ensorraré.\"},\n",
    "    ]\n",
    "\n",
    "response = crida_a_openai_amb_funcions(\n",
    "    model=MODEL,\n",
    "    messages=messages,\n",
    "    functions=functions,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "365536dcbde60510dc9073d6b991cd35db2d9bac356a11f5b64279a5e6708b97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
